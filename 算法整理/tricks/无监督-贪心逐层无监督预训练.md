# 贪心逐层预训练

### 动机

为了解决深层网络难以联合训练的问题

### 方法

假设某全连接网络总共有五层隐藏层，首先将输入数据传入第一层网络，通过无监督的方式训练本层网络至完全，得到网络的输出。再将这层的输出作为下一层网络的输入，传入第二层网络，并使用无监督算法单独训练第二层网络。以此类推，每次训练单层网络，并将上层网络的输出作为下一层网络的输入，直到所有隐藏层被训练完全。

### 原理

依赖于单层表示学习算法，每一层使用无监督学习预训练，将前一层的输出作为输入，输出数据的新的表示。  这个新的表示的分布有可能更能代表输入数据，即是更有效的特征。

单层表示学习算法：RBM、单层自编码器、稀疏编码模型等

### 特点

1. 逐层优化网络
2. 只能作为预训练部分，为后续算法确定初始化参数
3. 随着批标准化和Dropout等正则化方式的出现，该方法已经被淘汰。

